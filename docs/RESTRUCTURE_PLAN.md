# FTW Repository Restructure Plan

## Goals

1. **Reduce repo size**: Move large artifacts (lens_packs, models, results) out of git
2. **Enable distribution**: Lens packs and concept packs downloadable from HuggingFace
3. **Clean structure**: `src/` mirrors the FTW architecture layers
4. **Easy onboarding**: Clone repo, pip install, packs download on first use

---

## Target Directory Structure

```
ftw/                          # The repo
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ hat/                  # Layer 2: Headspace Ambient Transducer
â”‚   â”‚   â”œâ”€â”€ steering/         # Steering operations
â”‚   â”‚   â”‚   â”œâ”€â”€ hooks.py      # Steering hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ extraction.py # Concept vector extraction
â”‚   â”‚   â”‚   â”œâ”€â”€ manifold.py   # Manifold steering
â”‚   â”‚   â”‚   â”œâ”€â”€ ontology_field.py
â”‚   â”‚   â”‚   â””â”€â”€ subspace.py
â”‚   â”‚   â”œâ”€â”€ monitoring/       # Real-time concept monitoring
â”‚   â”‚   â”‚   â”œâ”€â”€ lens_manager.py
â”‚   â”‚   â”‚   â”œâ”€â”€ monitor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ detectors.py  # centroid, embedding, text detectors
â”‚   â”‚   â”‚   â””â”€â”€ deployment_manifest.py
â”‚   â”‚   â”œâ”€â”€ classifiers/      # Classifier infrastructure
â”‚   â”‚   â”‚   â”œâ”€â”€ classifier.py # MLPClassifier, LinearProbe
â”‚   â”‚   â”‚   â”œâ”€â”€ lens.py       # Lens abstraction
â”‚   â”‚   â”‚   â””â”€â”€ capture.py    # Activation capture
â”‚   â”‚   â””â”€â”€ utils/            # HAT utilities
â”‚   â”‚       â”œâ”€â”€ model_loader.py
â”‚   â”‚       â”œâ”€â”€ storage.py
â”‚   â”‚       â”œâ”€â”€ provenance.py
â”‚   â”‚       â””â”€â”€ gpu_cleanup.py
â”‚   â”‚
â”‚   â”œâ”€â”€ cat/                  # Layer 2.5: Conjoined Adversarial Tomograph
â”‚   â”‚   â””â”€â”€ divergence.py     # Divergence detection
â”‚   â”‚
â”‚   â”œâ”€â”€ map/                  # Layer 3: Mindmeld Architectural Protocol
â”‚   â”‚   â”œâ”€â”€ registry/         # Pack management + HF sync
â”‚   â”‚   â”‚   â”œâ”€â”€ registry.py
â”‚   â”‚   â”‚   â”œâ”€â”€ concept_pack.py
â”‚   â”‚   â”‚   â””â”€â”€ lens_pack.py
â”‚   â”‚   â”œâ”€â”€ graft/            # Concept grafting (from src/grafting/)
â”‚   â”‚   â”œâ”€â”€ meld/             # Meld operations (from src/encyclopedia/)
â”‚   â”‚   â””â”€â”€ training/         # Lens training (from src/training/)
â”‚   â”‚       â”œâ”€â”€ train_concept_pack_lenses.py
â”‚   â”‚       â”œâ”€â”€ sibling_ranking.py
â”‚   â”‚       â”œâ”€â”€ sumo_classifiers.py
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ be/                   # Layer 4: Bounded Experiencer
â”‚   â”‚   â”œâ”€â”€ bootstrap/        # (from src/bootstrap/)
â”‚   â”‚   â”œâ”€â”€ xdb/              # (from src/xdb/)
â”‚   â”‚   â”œâ”€â”€ workspace.py      # Global workspace loop
â”‚   â”‚   â”œâ”€â”€ motive_core.py    # Autonomic regulation
â”‚   â”‚   â””â”€â”€ experience.py     # Experience database
â”‚   â”‚
â”‚   â”œâ”€â”€ hush/                 # Layer 5: Safety Harnesses
â”‚   â”‚   â”œâ”€â”€ ush.py            # Universal Safety Harness
â”‚   â”‚   â””â”€â”€ csh.py            # Chosen Safety Harness
â”‚   â”‚
â”‚   â”œâ”€â”€ ask/                  # Layer 6: Agentic State Kernel
â”‚   â”‚   â”œâ”€â”€ contracts.py      # Lifecycle contracts
â”‚   â”‚   â””â”€â”€ tribes.py         # Tribal governance
â”‚   â”‚
â”‚   â””â”€â”€ ui/                   # Application layer
â”‚       â”œâ”€â”€ openwebui/        # OpenWebUI integration (from src/openwebui/)
â”‚       â”œâ”€â”€ streamlit/        # Streamlit apps (from src/ui/)
â”‚       â””â”€â”€ visualization/    # Visualization tools (from src/visualization/)
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ specification/        # FTW architecture spec
â”‚   â”œâ”€â”€ guides/               # User guides
â”‚   â””â”€â”€ api/                  # API reference
â”‚
â”œâ”€â”€ tests/                    # Test suite
â”œâ”€â”€ scripts/                  # Dev scripts, experiments
â”‚
â”œâ”€â”€ concept_packs/            # .gitignore'd, managed by registry
â”‚   â””â”€â”€ .registry.json
â”‚
â”œâ”€â”€ lens_packs/               # .gitignore'd, managed by registry
â”‚   â””â”€â”€ .registry.json
â”‚
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## HuggingFace Structure

### Organization: `ftw-project` (or similar)

```
huggingface.co/ftw-project/
â”œâ”€â”€ concept-pack-first-light      # Concept pack repo
â”œâ”€â”€ lens-apertus-8b-first-light   # Lens pack for Apertus 8B
â”œâ”€â”€ lens-gemma-3-4b-first-light   # Lens pack for Gemma 3 4B
â””â”€â”€ ...
```

### Concept Pack Repo Structure
```
concept-pack-first-light/
â”œâ”€â”€ pack.json                 # Pack metadata (spec_id, version, etc.)
â”œâ”€â”€ hierarchy.json            # Concept hierarchy
â”œâ”€â”€ concepts/
â”‚   â”œâ”€â”€ layer0/
â”‚   â”œâ”€â”€ layer1/
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md
```

### Lens Pack Repo Structure
```
lens-apertus-8b-first-light/
â”œâ”€â”€ pack_info.json            # Lens pack metadata
â”œâ”€â”€ layer0/
â”‚   â”œâ”€â”€ results.json          # Classifier metadata
â”‚   â””â”€â”€ classifiers/          # .pt files
â”œâ”€â”€ layer1/
â”œâ”€â”€ ...
â””â”€â”€ README.md
```

---

## MAP Registry Design

### Registry Files

Each pack directory has a `.registry.json`:

```json
{
  "schema_version": "1.0",
  "packs": {
    "first-light": {
      "source": "hf://ftw-project/concept-pack-first-light",
      "version": "1.0.0",
      "revision": "abc123",
      "synced_at": "2025-12-20T10:00:00Z",
      "modified": false,
      "size_bytes": 82000000
    },
    "my-custom-pack": {
      "source": "local",
      "version": "0.1.0",
      "created_at": "2025-12-19T...",
      "based_on": "first-light@1.0.0",
      "modified": true
    }
  }
}
```

### Registry API

```python
from ftw.map import registry

# List installed packs
registry.list_concept_packs()  # â†’ [{"name": "first-light", "source": "hf://...", ...}]
registry.list_lens_packs()

# Check for updates
registry.status()  # â†’ shows outdated, modified, etc.

# Pull from HuggingFace
registry.pull_concept_pack("first-light")
registry.pull_lens_pack("apertus-8b-first-light")

# Pull specific version
registry.pull_lens_pack("apertus-8b-first-light", version="1.2.0")

# Push to HuggingFace (requires auth)
registry.push_lens_pack("my-custom-pack", repo_id="username/my-lens-pack")

# Load a pack (auto-pulls if not present)
pack = registry.load_concept_pack("first-light")
lens = registry.load_lens_pack("apertus-8b-first-light", layer=2, concept="Deception")
```

---

## Migration Steps

### Phase 1: Implement Registry âœ… DONE
1. âœ… Create `src/map/registry.py` with core sync logic
2. âœ… Create `src/map/concept_pack.py` and `src/map/lens_pack.py` loaders
3. âœ… Add HuggingFace Hub integration (huggingface_hub library)
4. âœ… Add per-layer pull/push for lens packs
5. âœ… Remove old `src/registry/`, update all imports to `src.map`

### Phase 2: Upload to HuggingFace â³ DEFERRED
1. âœ… Use `HatCatFTW` organization on HuggingFace
2. âœ… Upload `concept_packs/first-light/` â†’ `concept-pack-first-light`
3. âš ï¸ Initial fp32 upload abandoned (26GB+ file sizes)
4. â³ Restart upload after bf16 pack trained and calibrated (~13GB)

### Phase 3: Clean Up Repo âœ… DONE
1. âœ… Update `.gitignore` to exclude `lens_packs/`, `concept_packs/`, `models/`, `results/`, `data/`, `logs/`

---

## Source Consolidation Phases

The goal is to align `src/` with the FTW architecture layers and eliminate duplication.

### Current Duplication Issues

**MLP Classifier defined 3x:** (RESOLVED - see Phase 4)
- `monitoring/temporal_monitor.py:SimpleMLP`
- `steering/hooks.py:LensClassifier`
- `training/classifier.py` (probably)

**Hook infrastructure duplicated:**
- `activation_capture/hooks.py` - forward hooks for capture
- `steering/hooks.py` - forward hooks for steering
- `monitoring/` - also registers hooks internally

### Phase 4: Unify Classifier Definition âœ… DONE
Created unified HAT module with:

1. âœ… `src/hat/__init__.py` - Module exports
2. âœ… `src/hat/classifier.py` - Unified classifier implementations:
   - `MLPClassifier`: Canonical 128â†’64â†’1 architecture (no sigmoid, raw logits)
   - `LinearProbe`: Simple linear probe for comparison
   - `load_classifier()`: Unified loader handling legacy/new state dict formats
   - `save_classifier()`: Unified saver
3. âœ… `src/hat/lens.py` - Lens abstraction:
   - `Lens`: Groups classifiers for a concept across layers
   - `ClassifierInfo`: Metadata for individual classifiers
   - Supports early/mid/late layer categories
   - Translates high-level measure/steer requests to appropriate classifiers

Updated imports (with backwards compatibility aliases):
- âœ… `steering/hooks.py`: `LensClassifier = MLPClassifier`, uses `load_classifier`
- âœ… `monitoring/temporal_monitor.py`: `SimpleMLP = MLPClassifier`, uses `load_classifier`
- âœ… `training/sibling_ranking.py`: Uses `load_classifier`, `save_classifier`
- âœ… `training/lens_validation.py`: Uses `load_classifier`

Multi-classifier metadata support:
- âœ… `src/data/version_manifest.py`: Extended `LensEntry` with `classifiers: Dict[int, ClassifierEntry]`
  - `ClassifierEntry`: layer, category, technique, metrics, file
  - `add_classifier()`: Accumulates classifiers across layers
  - `get_best_layer(category)`: Find best by F1 for early/mid/late
  - `to_hat_lens()`: Convert to HAT Lens object
- âœ… `src/map/lens_pack.py`: Updated loader with manifest/fallback modes
  - `get_lens_for_concept()`: Returns HAT Lens with all classifiers
  - Auto-detects old-format manifests and falls back to directory scanning

Verified: Training, monitoring, and steering all working.

### Phase 5: Move Steering to HAT âœ… DONE
1. âœ… Move `steering/hooks.py` â†’ `hat/hooks.py`
2. âœ… Move `steering/extraction.py` â†’ `hat/extraction.py`
3. âœ… Move `steering/manifold.py` â†’ `hat/manifold.py`
4. âœ… Move `steering/subspace.py` â†’ `hat/subspace.py`
5. âœ… Move `steering/evaluation.py` â†’ `hat/evaluation.py`
6. âœ… Move `steering/ontology_field.py` â†’ `hat/ontology_field.py`
7. âœ… Move `steering/detached_jacobian.py` â†’ `hat/detached_jacobian.py`
8. âœ… Update `src/hat/__init__.py` with all exports
9. âœ… Create backward-compat shims in `src/steering/`:
   - `src/steering/__init__.py` re-exports from `src.hat`
   - Each `src/steering/*.py` file re-exports from `src.hat.*`
10. Existing 30+ files importing from `src.steering` work unchanged

### Phase 6: Merge Activation Capture into HAT âœ… DONE
1. âœ… Review `activation_capture/hooks.py` - Contains ActivationCapture, ActivationConfig, BaselineGenerator
2. âœ… Copy `activation_capture/hooks.py` â†’ `hat/capture.py`
3. âœ… Move `activation_capture/model_loader.py` â†’ `utils/model_loader.py`
4. âœ… Update `src/hat/__init__.py` with capture exports
5. âœ… Update `src/utils/__init__.py` with ModelLoader export
6. âœ… Create backward-compat shims in `src/activation_capture/`:
   - `__init__.py` re-exports from `src.hat.capture`
   - `hooks.py` re-exports from `src.hat.capture`
   - `model_loader.py` re-exports from `src.utils.model_loader`
7. Existing files importing from `src.activation_capture` work unchanged

### Phase 7: Merge Monitoring into HAT âœ… DONE
1. âœ… Move `monitoring/temporal_monitor.py` â†’ `hat/monitor.py`
2. âœ… Move `monitoring/dynamic_lens_manager.py` â†’ `hat/lens_manager.py`
3. âœ… Move `monitoring/concept_dissonance.py` â†’ `cat/divergence.py`
4. âœ… Move `monitoring/sumo_temporal.py` â†’ `hat/sumo_temporal.py`
5. âœ… Move `monitoring/centroid_text_detector.py` â†’ `hat/centroid_detector.py`
6. âœ… Move `monitoring/embedding_text_detector.py` â†’ `hat/embedding_detector.py`
7. âœ… Move `monitoring/text_concept_lens.py` â†’ `hat/text_lens.py`
8. âœ… Move `monitoring/temporal_monitor_mapper.py` â†’ `hat/monitor_mapper.py`
9. âœ… Move `monitoring/deployment_manifest.py` â†’ `hat/deployment_manifest.py`
10. âœ… Create `src/cat/__init__.py` with divergence exports
11. âœ… Fix internal imports in moved files

### Phase 7.5: Clean Up Shim Directories âœ… DONE
Retired all backward-compat shims by updating imports directly:
1. âœ… `src/activation_capture/` - Updated 4 files, deleted directory
2. âœ… `src/steering/` - Updated 40+ files, deleted directory
3. âœ… `src/monitoring/` - Updated 58 files, deleted directory

All code now imports directly from new locations:
- `src.hat.*` - Unified Layer 2 (steering, monitoring, capture, classifiers)
- `src.cat.*` - Layer 2.5 (divergence detection)
- `src.utils.*` - Shared utilities (ModelLoader, storage, provenance)

### Phase 8: Organize HAT Subdirectories âœ… DONE
Created logical subdirectory structure within `hat/`:

1. âœ… `hat/steering/` - 8 files:
   - `hooks.py`, `extraction.py`, `manifold.py`, `ontology_field.py`, `subspace.py`
   - `evaluation.py`, `detached_jacobian.py`, `steering_manager.py`

2. âœ… `hat/monitoring/` - 8 files:
   - `lens_manager.py`, `monitor.py`, `sumo_temporal.py`, `monitor_mapper.py`
   - `centroid_detector.py`, `embedding_detector.py`, `text_lens.py`
   - `deployment_manifest.py`

3. âœ… `hat/classifiers/` - 3 files:
   - `classifier.py`, `lens.py`, `capture.py`

4. âœ… `hat/utils/` - 4 files (moved from `src/utils/`):
   - `model_loader.py`, `storage.py`, `provenance.py`, `gpu_cleanup.py`

5. âœ… Created `__init__.py` for each subdirectory
6. âœ… Updated `hat/__init__.py` to re-export from subdirectories
7. âœ… Updated 100+ external imports
8. âœ… Deleted `src/utils/`

### Phase 9: Consolidate MAP Layer âœ… DONE
1. âœ… Create `map/registry/` and move existing:
   - `registry.py`, `concept_pack.py`, `lens_pack.py`
2. âœ… Create `map/graft/` from `src/grafting/`
3. âœ… Create `map/meld/` from `src/encyclopedia/`
4. âœ… Move `src/training/` â†’ `map/training/`
5. âœ… Update all imports (32 files), delete empty directories
6. âœ… Updated `map/__init__.py` to re-export from all submodules

### Phase 10: Consolidate BE Layer âœ… DONE
1. âœ… Move `src/bootstrap/` â†’ `be/bootstrap/`
2. âœ… Move `src/xdb/` â†’ `be/xdb/`
3. âœ… Update internal imports (grafting â†’ src.map.graft)
4. âœ… Update external imports (src.xdb â†’ src.be.xdb)
5. âœ… Updated `be/__init__.py` to re-export from submodules

### Phase 11: Consolidate UI Layer âœ… DONE
1. âœ… Move `src/openwebui/` â†’ `ui/openwebui/`
2. âœ… Move current `src/ui/` contents â†’ `ui/streamlit/`
3. âœ… Move `src/visualization/` â†’ `ui/visualization/`
4. âœ… Update imports (visualization, streamlit internal)
5. âœ… Created `ui/__init__.py` with exports

### Phase 12: Final Cleanup âœ… DONE
1. âœ… Reviewed remaining directories (data/, interpreter/, testing/)
2. âœ… Created `src/data/__init__.py` with exports
3. âœ… Updated `src/README.md` with full architecture documentation
4. âœ… Verified all layer imports work end-to-end

### Phase 13: Documentation âœ… DONE
1. âœ… Batch updated all old import paths in docs/ and .claude/
2. âœ… Updated root .md files (README.md, QUICKSTART.md, etc.)
3. âœ… Moved `src/interpreter/` â†’ `src/hat/interpreter/`
4. âœ… Updated `src/README.md` with complete architecture guide

---

## .gitignore Additions

```gitignore
# Pack directories (managed by registry)
/concept_packs/
/lens_packs/

# Downloaded models
/models/

# Generated outputs
/results/
/logs/
/data/

# Keep pack registries if you want reproducible environments
# !concept_packs/.registry.json
# !lens_packs/.registry.json
```

---

## Performance Optimization Phases

### Current State

The codebase has performance issues from mixed numpy/torch usage:
- **43** `.numpy()` calls in `src/` (GPUâ†’CPU round-trips)
- **117** `np.ndarray` type hints in GPU-adjacent code
- Numpy linear algebra ops on data that should stay on GPU
- Dtype mismatches: models run bfloat16, some lenses trained float32

### Phase 14: Torch-Native Conversion (Assessment) âœ“ COMPLETE

**Goal**: Map all numpy usage in GPU-adjacent code and plan conversion order.

**Status**: Complete. Benchmark showed:
- Single numpy ops faster than single torch GPU ops (kernel launch ~10Âµs overhead)
- Batched torch 10x faster than sequential
- GPUâ†’CPUâ†’GPU round-trips are primary waste

**Priority Order** (user-specified):
1. âœ“ Eliminate GPUâ†’CPUâ†’GPU round-trips in hot path
2. âœ“ Batch lens inference in `detect_and_expand`
3. âœ“ Verify batched accuracy matches sequential
4. âœ“ Batch steering application (already batched per-layer)

| Module | Numpy Uses | Downstream | Priority |
|--------|------------|------------|----------|
| `hat/steering/hooks.py` | `np.dot` projections | manifold, hush | High |
| `hat/steering/manifold.py` | norm, blend ops | behavioral eval | Medium |
| `hat/monitoring/centroid_detector.py` | `np.dot` similarity | divergence | Low |
| `hat/monitoring/embedding_detector.py` | `np.dot` similarity | divergence | Low |
| `hush/autonomic_steering.py` | Full numpy backend | hush_integration | High |
| `cat/divergence.py` | cosine similarity | openwebui | Medium |
| `map/training/sumo_classifiers.py` | activations, vectors | training scripts | Medium |

Tasks:
1. [ ] Run `grep -rn "\.numpy()\|np\." src/` and categorize by hot-path vs cold-path
2. [ ] For each hot-path module, identify downstream scripts that may break
3. [ ] Create test cases capturing current numerical behavior
4. [ ] Document conversion order respecting dependencies

### Phase 15: Torch-Native Conversion (Core Modules) ğŸ”„ IN PROGRESS

Convert core modules that are in the inference hot-path:

#### 15.1: `hat/steering/hooks.py` âœ“ COMPLETE
- ~~Replace `np.dot(a, b)` â†’ `a @ b` or `torch.dot()`~~
- ~~Replace `np.linalg.norm()` â†’ `tensor.norm()`~~
- âœ“ Eliminated 4 GPUâ†’CPUâ†’GPU round-trips:
  - Line ~923: gradient steering (now stays on GPU with clone+requires_grad)
  - Line ~1024: contrastive steering (same pattern)
  - Line ~1234: multi-classifier steering (hidden_base stays on GPU)
  - Line ~1195: layer vector extraction (torch.norm instead of np.linalg.norm)
- Verify: steering tests pending

#### 15.2: `hush/autonomic_steering.py`
- Full rewrite from numpy to torch
- `SteeringChannel` â†’ torch tensor state
- `AutonomicSteerer` â†’ batched torch ops
- Verify: hush integration tests, intervention behavior unchanged

#### 15.3: `hat/steering/manifold.py`
- Convert blending/norm operations
- Verify: manifold steering tests

#### 15.4: `hat/monitoring/*_detector.py`
- Convert similarity calculations
- Verify: detection scores match

### Phase 16: Torch-Native Conversion (Support Modules)

Convert modules not in hot-path but still doing unnecessary conversions:

#### 16.1: `cat/divergence.py`
- Convert cosine similarity
- Verify: divergence detection unchanged

#### 16.2: `map/training/sumo_classifiers.py`
- Already partially done (bfloat16 default)
- Remove remaining `.numpy()` where not needed for sklearn/serialization
- Verify: training produces same quality lenses

#### 16.3: Remaining files
- Sweep through all 43 `.numpy()` calls
- Convert where beneficial, document where numpy is required (sklearn, disk I/O)

### Phase 17: CUDA Kernel Assessment

**Goal**: Profile hot paths and determine if custom kernels are warranted.

#### 17.1: Profiling
```bash
python -m torch.profiler tests/profile_lens_inference.py
python -m torch.profiler tests/profile_autonomic_steering.py
```

Questions to answer:
- What % of time is kernel launch overhead vs compute?
- Are there many small sequential kernels that could fuse?
- What's the memory bandwidth utilization?

#### 17.2: Identify Fusion Candidates

**Lens Manager** (`detect_and_expand`):
```
Current: N separate lens forward passes
Fused:   Single batched forward with stacked weights
```

**Autonomic Steering**:
```
Current: Loop over channels computing corrections
Fused:   Batched correction computation
```

#### 17.3: Benchmark Alternatives

| Alternative | Effort | Expected Gain | Try First? |
|-------------|--------|---------------|------------|
| `torch.compile()` | Low | 2-3x | Yes |
| `torch.jit.script()` | Low | 1.5-2x | Yes |
| Triton kernels | Medium | 3-5x | If above insufficient |
| `torch.cuda.graphs` | Low | 2x | For repeated ops |
| Raw CUDA | High | 5-10x | Only if critical |

### Phase 18: Lens Inference Optimization âœ“ COMPLETE

**Goal**: Sub-millisecond per-token lens inference.

#### 18.1: Batched Lens Forward âœ“ COMPLETE
- âœ“ Created `BatchedLensBank` class in lens_manager.py
- âœ“ Stacks all lens weights into batched tensors: W1[N,128,input], W2[N,64,128], W3[N,1,64]
- âœ“ Uses `torch.bmm` for batched matmul across all lenses
- âœ“ Integrated into `DynamicLensManager.detect_and_expand()`
- âœ“ Lazy rebuild with dirty flag when lenses change

**Results** (50 lenses, 100 iterations):
- Sequential: 2.43 ms
- Batched: 0.41 ms
- **Speedup: 6x**

Test: `tests/test_batched_lens_inference.py`
- Verified numerical accuracy (max diff < 1e-5)
- Handles bfloat16/float32 dtypes correctly

#### 18.2: torch.compile() Integration
- Deferred - 6x speedup sufficient for current needs
- Can add `@torch.compile(mode="reduce-overhead")` if more needed

#### 18.3: Optional - Triton Kernel
- Deferred - batched bmm approach is sufficient

### Phase 19: BFloat16 Lens Optimization âœ“ COMPLETE

**Goal**: Reduce lens pack size and loading time.

#### 19.1: Training Defaults âœ“
- `train_simple_classifier()` now defaults to `dtype=torch.bfloat16`
- New lenses trained at half precision automatically

**REGRESSION FIX (Phase 22)**: BFloat16 training without input normalization caused
gradient saturation. Higher layers have ~30,000x larger activation magnitudes than lower
layers. With float32, gradients could survive saturation; bfloat16's limited precision
killed them completely, causing all models to predict constant 0.667 F1 (all one class).

**Fix**: Added `normalize_inputs=True` to `train_simple_classifier()` which applies
per-sample normalization (matching `nn.LayerNorm` at inference). This ensures training
and inference see the same normalized inputs regardless of layer magnitude.

#### 19.2: Conversion Script âœ“
- Created `scripts/convert_lenses_to_bf16.py`
- Parallel conversion of existing fp32 packs to bf16
- Preserves all metadata, updates pack_info.json

#### 19.3: Direct GPU Loading âœ“
- Changed `torch.load(..., map_location='cpu')` to `map_location=self.device`
- Eliminates CPUâ†’GPU copy overhead

**Results:**
| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Pack size | 26.64 GB | 13.34 GB | **50% smaller** |
| Per-lens load (GPU) | 4.25 ms | 0.65 ms | **6.5x faster** |
| Child loading (72 lenses) | 186 ms | 100 ms | **46% faster** |
| Detection avg | 137 ms | 108 ms | **21% faster** |

Converted pack: `lens_packs/apertus-8b_first-light-bf16`

### Phase 20: Training Optimization

**Goal**: Faster lens training for large concept packs.

#### 20.1: Batched Activation Extraction
- Current: One prompt at a time
- Proposed: Batch extraction with padding

#### 20.2: Parallel Concept Training
- Train multiple concepts concurrently (CUDA streams)
- Or distributed across GPUs

### Phase 21: Tiered Memory Architecture ğŸ”„ IN PROGRESS

**Goal**: Minimize lens loading latency during hierarchical expansion.

**Problem Identified**: Benchmark showed 300-600ms child loading times during `detect_and_expand`:
- Batched inference on base lenses: ~6ms (excellent)
- Child loading from disk: ~3.5ms per lens (bottleneck)
- Most time spent in `torch.load()` deserialization + GPU transfer

**Solution**: Four-tier memory hierarchy:

```
1. HOT VRAM      â†’ BatchedLensBank, scored every token (~6ms for 269 lenses)
2. WARM VRAM    â†’ GPU tensors waiting for parent activation
3. TEPID RAM     â†’ CPU tensors pre-loaded at startup, just .to(device) when needed
4. COLD DISK     â†’ Only if RAM can't hold pack (fallback)
```

#### 21.1: Tepid Cache Implementation âœ“ COMPLETE
- Added `tepid_cache: Dict[Tuple[str,int], Dict[str, Tensor]]` for CPU tensors
- Added `preload_pack_to_ram()` method to load entire pack to RAM at startup
- Modified `_load_concepts()` to check tepid cache before disk:
  - Already active â†’ skip
  - In warm cache (VRAM) â†’ move to active
  - In tepid cache (RAM) â†’ `.to(device)` transfer
  - Otherwise â†’ `torch.load()` from disk

#### 21.2: Benchmark Results

Pre-load stats:
- 7947 concepts loaded to RAM
- 8075 MB (~8GB) in 12 seconds (one-time startup cost)

| Metric | Before (disk) | After (tepid RAM) | Change |
|--------|--------------|-------------------|--------|
| Avg detection | 57ms | 48ms | -16% |
| P50 | 34ms | 28ms | -18% |
| P95 | 192ms | 154ms | -20% |
| Overhead | 169% | 143% | -26% |

Tepid cache working (182 tepid_hits per detection), but sequential `.to(device)` calls still have overhead (~2ms per lens).

#### 21.3: Further Optimizations (Pending)
- [ ] Batch GPU transfers: stack tensors before `.to(device)`
- [ ] Pre-warm likely children during prompt processing
- [ ] Consider pinned memory for faster CPUâ†’GPU transfers
- [ ] Add `max_ram_mb` budget configuration

### Phase 22: Training Pipeline Fixes âœ“ COMPLETE

**Goal**: Fix training regressions introduced in earlier phases.

#### 22.1: Input Normalization âœ“
**Problem**: Phase 19's bfloat16 switch broke training for higher layers.
- Higher layers have ~30,000x larger activation magnitudes than lower layers
- First linear layer output immediately saturated sigmoid
- Gradients vanished, model predicted constant value (F1=0.667)

**Fix**: Added `normalize_inputs=True` to `train_simple_classifier()`:
```python
# Per-sample normalization (matches nn.LayerNorm at inference)
train_mean = X_train.mean(axis=1, keepdims=True)
train_std = X_train.std(axis=1, keepdims=True) + 1e-8
X_train = (X_train - train_mean) / train_std
```

#### 22.2: Stuck Training Detection âœ“
**Problem**: `train_concept()` would loop forever on same data if model never graduated.
- Training data selected deterministically (first N samples, no shuffle)
- `validation_cycle` only incremented after graduation + validation failure
- If graduation never happened, same data reused every iteration

**Fix**: Added `iterations_this_cycle` counter with auto-escalation:
- After 3 iterations without graduation, increment `validation_cycle`
- This requests more samples (40 â†’ 80 â†’ 120...) to give model more to work with

#### 22.3: Import Path Fixes âœ“
**Problem**: 32 files had incorrect `sys.path` calculations after restructure.
- Files in `src/<module>/<submodule>/` needed 4 levels of `.parent`
- Files in `scripts/<category>/` needed 3 levels of `.parent`
- Many had incorrect counts, causing `ModuleNotFoundError`

**Fix**: Updated all affected files with correct path calculations.

---

## Open Questions

1. **Pack naming convention**: `lens-{model}-{concept-pack}` or `{model}_{concept-pack}`?
2. **Concept packs in git vs HF**: Small enough to check in? Or always from HF?
3. **Registry lockfile**: Check in `.registry.json` for reproducibility?
4. **Organization name**: `ftw-project`, `fractal-transparency-web`, `hatcat`?
5. **Triton vs raw CUDA**: Is Triton mature enough for production kernels?
6. **torch.compile stability**: Version pin needed for reproducibility?
