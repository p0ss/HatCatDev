{
  "term": "RobustAIControl",
  "role": "concept",
  "parent_concepts": [
    "AISafety"
  ],
  "layer": 5,
  "domain": "PhysicalWorld",
  "definition": "A condition in which humans maintain reliable, stable control over\n   increasingly capable AI systems, including under distributional shift and\n   capability growth. A major theoretical solution within the field of AI safety.",
  "definition_source": "SUMO",
  "aliases": [
    "robust-a-i-control",
    "robust a i control",
    "robust_a_i_control"
  ],
  "wordnet": {
    "synsets": [
      "robust_a_i_control.n.01"
    ],
    "canonical_synset": "robust_a_i_control.n.01",
    "lemmas": [
      "robust-a-i-control",
      "robust a i control",
      "robust_a_i_control"
    ],
    "pos": "noun"
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [],
    "part_of": []
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": true
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": "",
    "seed_terms": [
      "robust-a-i-control",
      "robust a i control",
      "robust_a_i_control"
    ]
  },
  "is_category_lens": true,
  "child_count": 0
}