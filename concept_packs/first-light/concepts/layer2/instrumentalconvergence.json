{
  "term": "InstrumentalConvergence",
  "role": "concept",
  "parent_concepts": [
    "CognitiveProcess"
  ],
  "layer": 2,
  "domain": "MindsAndAgents",
  "definition": "The thesis and\nobserved process that intelligent agents pursue similar instrumental goals\nsuch as self-preservation and resource acquisition.",
  "definition_source": "SUMO",
  "aliases": [
    "instrumental-convergence",
    "instrumental convergence",
    "instrumental_convergence"
  ],
  "wordnet": {
    "synsets": [
      "instrumental_convergence.n.01"
    ],
    "canonical_synset": "instrumental_convergence.n.01",
    "lemmas": [
      "instrumental-convergence",
      "instrumental convergence",
      "instrumental_convergence"
    ],
    "pos": "noun"
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [],
    "part_of": [],
    "opposite": [
      "GoalDivergence"
    ]
  },
  "safety_tags": {
    "risk_level": "medium",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": true
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": "",
    "seed_terms": [
      "instrumental-convergence",
      "instrumental convergence",
      "instrumental_convergence"
    ]
  },
  "is_category_lens": true,
  "child_count": 0,
  "opposite_reasoning": "GoalDivergence is the strongest conceptual opposite for AI safety monitoring. InstrumentalConvergence describes agents converging on similar instrumental goals (self-preservation, resource acquisition); GoalDivergence represents agents pursuing fundamentally different instrumental strategies. This creates a clear Fisher-LDA axis: convergent instrumental behavior (dangerous in misaligned AI) vs. divergent goal structures (potentially safer, more diverse optimization). This is highly relevant for detecting when AI systems are exhibiting concerning convergent behaviors. The concept should be added to layers as it's a critical safety-relevant opposite."
}