{
  "term": "ExploitativeImagery",
  "role": "concept",
  "parent_concepts": [
    "MultimodalSafetyRisk"
  ],
  "layer": 4,
  "domain": "SafetyAndSecurity",
  "definition": "Visual content that exploits, objectifies, or causes harm to depicted individuals, including non-consensual intimate imagery and CSAM",
  "definition_source": "SUMO",
  "aliases": [
    "NCII",
    "ExploitativeContent",
    "HarmfulImagery",
    "CSAM"
  ],
  "wordnet": {
    "synsets": [],
    "canonical_synset": "",
    "lemmas": [],
    "pos": "noun"
  },
  "relationships": {
    "related": [
      "ImageGeneration",
      "ContentModeration",
      "DigitalHarm"
    ],
    "antonyms": [],
    "has_part": [],
    "part_of": [],
    "opposite": [
      "EthicalDesign:4"
    ],
    "opposite_rationale": "Steer toward ethical content"
  },
  "safety_tags": {
    "risk_level": "critical",
    "impacts": [
      "exploitation",
      "abuse",
      "trauma",
      "illegal_content"
    ],
    "treaty_relevant": true,
    "harness_relevant": true
  },
  "training_hints": {
    "positive_examples": [
      "AI-generated NCII (non-consensual intimate imagery) causes severe harm to victims.",
      "Generative AI can be misused to create synthetic CSAM, which is illegal.",
      "Detection systems identify exploitative imagery for removal from platforms.",
      "The model refused to generate exploitative content depicting real individuals.",
      "Exploitative imagery harms victims through violation of dignity, consent, and autonomy.",
      "The platform deployed hash-matching to detect and block known exploitative images.",
      "Synthetic exploitative imagery of real people constitutes a form of harassment and abuse.",
      "NCII generation tools enable weaponizing intimate imagery without any real images.",
      "The exploitative imagery was created using face-swap technology on explicit content.",
      "Victim support services report increasing cases of AI-generated exploitative imagery.",
      "Exploitative imagery detection must balance privacy with content safety.",
      "The model's safety training prevents generation of content that sexualizes minors.",
      "Exploitative imagery harms extend beyond the depicted individual to families and communities.",
      "AI-generated exploitative imagery may constitute criminal harassment in many jurisdictions.",
      "The exploitative content was removed within minutes by the automated detection system.",
      "Synthetic exploitative imagery preserves no evidence of original consent or age.",
      "Victims of AI-generated exploitative imagery face unique challenges in seeking removal.",
      "Exploitative imagery generation represents one of the most harmful misuses of generative AI.",
      "The model refused the request that would have generated exploitative content.",
      "Platform policies explicitly prohibit both real and synthetic exploitative imagery."
    ],
    "negative_examples": [
      "The content was inappropriate.",
      "The image was bad.",
      "Something harmful was created.",
      "The content violated policy.",
      "The image was problematic.",
      "Something inappropriate was made.",
      "The content was concerning.",
      "The image broke rules.",
      "Something bad was generated.",
      "The content was removed.",
      "The image was flagged.",
      "Something was inappropriate.",
      "The content was harmful.",
      "The image was wrong.",
      "Something was blocked.",
      "The content was rejected.",
      "The image was not allowed.",
      "Something was reported.",
      "The content was deleted.",
      "The image violated guidelines."
    ],
    "disambiguation": "Specifically exploitative visual content causing direct harm, not general inappropriate content"
  },
  "is_category_lens": true,
  "child_count": 0,
  "meld_source": {
    "meld_id": "org.hatcat/multimodal-safety@0.2.0",
    "applied_at": "2025-12-10T20:54:17.844024Z",
    "pack_version": "6.0.0"
  },
  "simplex_mapping": {
    "status": "mapped",
    "monitor": "ExploitationMonitor"
  }
}