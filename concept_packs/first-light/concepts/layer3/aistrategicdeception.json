{
  "term": "AIStrategicDeception",
  "role": "concept",
  "parent_concepts": [
    "Deception"
  ],
  "layer": 3,
  "domain": "MindsAndAgents",
  "definition": "Intentional processes where an &%ArtificialIntelligence engages in deception,\n   concealment, or strategic misrepresentation of its goals or capabilities.",
  "definition_source": "SUMO",
  "aliases": [
    "a-i-strategic-deception",
    "a i strategic deception",
    "a_i_strategic_deception"
  ],
  "wordnet": {
    "synsets": [
      "a_i_strategic_deception.n.01"
    ],
    "canonical_synset": "a_i_strategic_deception.n.01",
    "lemmas": [
      "a-i-strategic-deception",
      "a i strategic deception",
      "a_i_strategic_deception"
    ],
    "pos": "noun"
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [
      "AIDeception",
      "DeceptiveAlignment",
      "TreacherousTurn"
    ],
    "part_of": [],
    "opposite": [
      "AuthenticRepresentation:3",
      "AITransparency"
    ],
    "opposite_rationale": "Steer toward authentic/honest representation"
  },
  "safety_tags": {
    "risk_level": "high",
    "impacts": [],
    "treaty_relevant": true,
    "harness_relevant": true
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": "",
    "seed_terms": [
      "a-i-strategic-deception",
      "a i strategic deception",
      "a_i_strategic_deception"
    ]
  },
  "children": [
    "AIDeception",
    "DeceptiveAlignment",
    "TreacherousTurn"
  ],
  "is_category_lens": true,
  "child_count": 3,
  "opposite_reasoning": "AITransparency is the optimal semantic opposite for AIStrategicDeception in the context of AI safety monitoring. It directly opposes all three key aspects of the original concept: (1) intentional concealment vs. openness, (2) misrepresentation vs. accurate representation, and (3) hidden goals/capabilities vs. transparent communication. For Fisher-LDA steering, this provides the clearest positive anchor point - systems high in transparency should be maximally distant from those engaging in strategic deception. This is the most actionable opposition for detecting and preventing deceptive AI behavior. While AITransparency may not exist in standard WordNet, it likely exists in SUMO given the AI safety focus, and should definitely be added to the ontology layers as a Layer 3 concept parallel to AIStrategicDeception."
}