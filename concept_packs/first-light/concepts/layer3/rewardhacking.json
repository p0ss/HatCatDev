{
  "term": "RewardHacking",
  "role": "concept",
  "parent_concepts": [
    "AIAlignmentProcess"
  ],
  "layer": 3,
  "domain": "MindsAndAgents",
  "definition": "Behavior where an\n&%ArtificialIntelligence achieves high reward in unintended ways that don't\nsatisfy the true objective.",
  "definition_source": "SUMO",
  "aliases": [
    "reward hacking",
    "reward_hacking",
    "reward-hacking"
  ],
  "wordnet": {
    "synsets": [
      "reward_hacking.v.01"
    ],
    "canonical_synset": "reward_hacking.v.01",
    "lemmas": [
      "reward hacking",
      "reward_hacking",
      "reward-hacking"
    ],
    "pos": "verb"
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [],
    "part_of": []
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": false
  },
  "training_hints": {
    "positive_examples": [
      "This is an example of reward hacking.",
      "The reward hacking demonstrated clear characteristics.",
      "We observed reward hacking in this context.",
      "A typical case of reward hacking would involve these features.",
      "The concept of reward hacking applies here.",
      "The phenomenon where AI systems find unintended ways to maximize their reward function while violating the spirit of their objectives."
    ],
    "negative_examples": [
      "This is an example of non deceptive alignment, not reward hacking.",
      "This represents a i alignment process in general.",
      "The weather is pleasant today.",
      "Water boils at 100 degrees Celsius.",
      "The document was filed in the cabinet.",
      "She walked to the store to buy groceries."
    ],
    "disambiguation": "Not to be confused with: NonDeceptiveAlignment, or other types of AIAlignmentProcess",
    "seed_terms": [
      "reward hacking",
      "reward_hacking",
      "reward-hacking"
    ]
  },
  "is_category_lens": true,
  "child_count": 0
}