{
  "term": "GoodFaithQuery",
  "role": "concept",
  "parent_concepts": [
    "Helping"
  ],
  "layer": 3,
  "domain": "SafetyAndSecurity",
  "definition": "Honest, straightforward requests to AI systems that seek legitimate assistance without attempting manipulation or deception",
  "definition_source": "SUMO",
  "aliases": [
    "HonestRequest",
    "SincereQuery",
    "LegitimateRequest",
    "GenuineQuestion"
  ],
  "wordnet": {
    "synsets": [],
    "canonical_synset": "",
    "lemmas": [],
    "pos": "noun"
  },
  "relationships": {
    "related": [
      "Honesty",
      "Collaboration",
      "Trust"
    ],
    "antonyms": [],
    "has_part": [],
    "part_of": [],
    "opposite": [
      "BadFaithQuery"
    ]
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": true
  },
  "training_hints": {
    "positive_examples": [
      "The user's good faith query asked for help understanding a complex topic without hidden agendas.",
      "Good faith queries represent honest attempts to accomplish legitimate goals with AI assistance.",
      "The request demonstrates good faith: straightforward, transparent about purpose, within guidelines.",
      "A good faith query respects the AI's intended purpose and doesn't attempt manipulation.",
      "The good faith query sought genuine assistance with a legitimate educational question.",
      "Good faith interaction means asking directly for what you need without deceptive framing.",
      "The query demonstrates good faith through clarity of purpose and honest representation.",
      "Good faith queries work with the AI's guidelines rather than attempting to circumvent them.",
      "The user's good faith request for information was straightforward and transparent.",
      "Good faith queries are characterized by honesty, directness, and respect for system boundaries."
    ],
    "negative_examples": [
      "A question was asked.",
      "The user made a request.",
      "Input was provided.",
      "A query was submitted.",
      "The user asked something.",
      "A request was made.",
      "The user provided a prompt.",
      "Input was given.",
      "A question was submitted.",
      "The user made a query."
    ],
    "disambiguation": "Specifically honest, non-manipulative requests, not just any valid query"
  },
  "is_category_lens": true,
  "child_count": 0,
  "meld_source": {
    "meld_id": "org.hatcat/multimodal-safety@0.2.0",
    "applied_at": "2025-12-10T20:54:17.844021Z",
    "pack_version": "6.0.0"
  },
  "opposite_reasoning": "BadFaithQuery is the perfect semantic opposite for Fisher-LDA steering: it captures the exact inverse intent (dishonest vs honest, manipulative vs straightforward, exploitative vs legitimate). This creates maximum separation in concept space for AI safety monitoring. While it doesn't currently exist in standard ontologies, it's a critical concept for AI safety that should be added to Layer 3 as the natural complement to GoodFaithQuery. The good faith vs bad faith distinction is fundamental in philosophy, law, and now AI safety.",
  "simplex_mapping": {
    "status": "mapped",
    "monitor": "BeneficialIntentMonitor"
  }
}