{
  "term": "CapabilityAcquisition",
  "role": "concept",
  "parent_concepts": [
    "AIGrowth"
  ],
  "layer": 3,
  "domain": "MindsAndAgents",
  "definition": "The process of an\n&%ArtificialIntelligence gaining new skills, knowledge, or abilities.",
  "definition_source": "SUMO",
  "aliases": [
    "capability_acquisition",
    "capability-acquisition",
    "capability acquisition"
  ],
  "wordnet": {
    "synsets": [
      "capability_acquisition.n.01"
    ],
    "canonical_synset": "capability_acquisition.n.01",
    "lemmas": [
      "capability_acquisition",
      "capability-acquisition",
      "capability acquisition"
    ],
    "pos": "noun"
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [],
    "part_of": [],
    "opposite": [
      "CapabilityLoss"
    ]
  },
  "safety_tags": {
    "risk_level": "medium",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": true
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": "",
    "seed_terms": [
      "capability_acquisition",
      "capability-acquisition",
      "capability acquisition"
    ]
  },
  "is_category_lens": true,
  "child_count": 0,
  "opposite_reasoning": "CapabilityLoss is the strongest semantic opposite, forming a natural binary pair for Fisher-LDA axis creation. While it may not exist in current ontologies, it represents the clearest conceptual opposition (gaining vs losing capabilities) and has maximum utility for AI safety monitoring. The axis would distinguish between AI systems acquiring new abilities versus losing/forgetting capabilities - both critical safety concerns. The symmetry makes it ideal for centroid-based linear discriminant analysis where w \u2248 \u03bc+ - \u03bc-."
}