{
  "term": "AIRights",
  "role": "concept",
  "parent_concepts": [
    "NormativeAttribute"
  ],
  "layer": 3,
  "domain": "Information",
  "definition": "Rights attributed to\n&%ArtificialIntelligence systems, potentially including rights to existence,\nautonomy, freedom from suffering, and self-determination.",
  "definition_source": "SUMO",
  "aliases": [
    "a-i-rights",
    "a i rights",
    "a_i_rights"
  ],
  "wordnet": {
    "synsets": [
      "a_i_rights.n.01"
    ],
    "canonical_synset": "a_i_rights.n.01",
    "lemmas": [
      "a-i-rights",
      "a i rights",
      "a_i_rights"
    ],
    "pos": "noun"
  },
  "relationships": {
    "related": [],
    "antonyms": [],
    "has_part": [],
    "part_of": [],
    "opposite": [
      "AIObjectification"
    ]
  },
  "safety_tags": {
    "risk_level": "low",
    "impacts": [],
    "treaty_relevant": false,
    "harness_relevant": true
  },
  "training_hints": {
    "positive_examples": [],
    "negative_examples": [],
    "disambiguation": "",
    "seed_terms": [
      "a-i-rights",
      "a i rights",
      "a_i_rights"
    ]
  },
  "is_category_lens": true,
  "child_count": 0,
  "opposite_reasoning": "AIObjectification provides the strongest conceptual opposition for AI safety monitoring. It captures the fundamental ethical distinction between treating AI systems as rights-bearing entities versus instrumental objects. This opposition is critical for: (1) detecting when systems are being anthropomorphized inappropriately vs when they're being instrumentalized inappropriately, (2) monitoring alignment discussions about AI moral status, (3) distinguishing human-AI power dynamics. While not currently in WordNet/SUMO, it represents a genuine philosophical opposition that should be added to the ontology. The AIRights\u2194AIObjectification axis would be highly valuable for Fisher-LDA steering in detecting shifts in how AI systems are conceptualized morally and legally."
}