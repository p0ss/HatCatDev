---
license: apache-2.0
base_model: swiss-ai/Apertus-8B-2509
tags:
  - interpretability
  - probes
  - concept-detection
  - hatcat
  - ftw
library_name: pytorch
pipeline_tag: other
---

# Apertus-8B SUMO-WordNet Lens Pack v4.2

Concept detection lenses for [Apertus-8B](https://huggingface.co/swiss-ai/Apertus-8B-2509), trained as part of the [HatCat / Fractal Telescope Web](https://github.com/p0ss/HatCat) interpretability stack.

## What are these?

These are **trained linear probes** (lenses) that detect concept activations in a language model's hidden states. Each lens is a small classifier that fires when its corresponding concept is active during inference.

This lens pack contains **7,684 concepts** across **5 layers**, organized into a hierarchical ontology based on SUMO-WordNet.

## Usage

```python
from hatcat.registry import LensPackRegistry

# Load the lens pack
registry = LensPackRegistry()
lens_pack = registry.load("HatCatFTW/apertus-8b-sumo-wordnet-v4.2")

# Get concept scores during inference
with lens_pack.attach(model) as hat:
    outputs = model.generate(inputs)
    concept_scores = hat.get_scores()  # Dict[concept_id, float]
```

See the [HatCat documentation](https://github.com/p0ss/HatCat) for full usage.

## Training Details

| Parameter | Value |
|-----------|-------|
| Base model | swiss-ai/Apertus-8B-2509 |
| Concept pack | sumo-wordnet-v4 (v4.2.0) |
| Total concepts | 7,684 |
| Layers | 0, 1, 2, 3, 4 |
| Training samples per concept | 50 positive, 50 negative (adaptive) |
| Test samples per concept | 20 positive, 20 negative |
| Minimum F1 threshold | 0.85 (strict validation) |
| Sibling refinement | Yes (margin ranking loss) |

### Performance Summary

| Layer | Concepts | Mean F1 |
|-------|----------|---------|
| 0 | 5 | ~0.95 |
| 1 | 56 | ~0.95 |
| 2 | 1,051 | ~0.95 |
| 3 | 2,460 | ~0.95 |
| 4 | 4,112 | ~0.95 |

*All lenses pass the 0.85 F1 threshold with sibling refinement.*

## Ontology Structure

The concepts are organized hierarchically across 5 domains:

- **CreatedThings** (1,930 concepts) - Artifacts, tools, structures
- **MindsAndAgents** (1,648 concepts) - Cognitive processes, agents, intentions
- **PhysicalWorld** (1,567 concepts) - Physical objects, processes, properties
- **Information** (1,373 concepts) - Data, propositions, representations
- **LivingThings** (1,166 concepts) - Organisms, biological processes

Each layer represents a different depth in the ontology:
- Layer 0: Root concepts (most abstract) - 5 domain roots
- Layer 1: High-level categories - 56 concepts
- Layer 2: Mid-level concepts - 1,051 concepts
- Layer 3: Specific concepts - 2,460 concepts
- Layer 4: Leaf concepts (most specific) - 4,112 concepts

## File Structure

```
apertus-8b-sumo-wordnet-v4.2/
├── README.md               # This file
├── pack_info.json          # Pack metadata
├── layer0/
│   └── *_classifier.pt     # 5 lenses
├── layer1/
│   └── *_classifier.pt     # 56 lenses
├── layer2/
│   └── *_classifier.pt     # ~1,051 lenses
├── layer3/
│   └── *_classifier.pt     # ~2,460 lenses
├── layer4/
│   └── *_classifier.pt     # 4,112 lenses
└── logs/
    └── training_*.log      # Training logs with per-concept metrics
```

## Intended Use

These lenses are designed for:

- **Interpretability research** - Understanding what concepts a model represents
- **Concept monitoring** - Real-time detection of concept activations during inference
- **Steering experiments** - Using lens directions for activation steering
- **Alignment research** - Building oversight systems (CAT, HUSH) on top of concept detection

## Limitations

- Lenses are trained on synthetic examples generated by an LLM - they detect concepts as represented in training data, not ground truth
- Performance varies by concept; some abstract concepts are harder to detect than concrete ones
- Sibling confusion can occur for closely related concepts (mitigated by sibling refinement)
- Lenses are specific to this base model; they won't transfer to other architectures

## Citation

```bibtex
@software{hatcat2025,
  title = {HatCat: Headspace Ambient Transducer},
  author = {HatCat Contributors},
  year = {2025},
  url = {https://github.com/p0ss/HatCat}
}
```

## License

Apache 2.0 - see [LICENSE](https://github.com/p0ss/HatCat/blob/main/LICENSE)
