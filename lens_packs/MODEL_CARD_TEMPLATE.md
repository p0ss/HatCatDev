---
license: apache-2.0
base_model: {BASE_MODEL_ID}
tags:
  - interpretability
  - probes
  - concept-detection
  - hatcat
  - ftw
library_name: pytorch
pipeline_tag: other
---

# {LENS_PACK_NAME}

Concept detection lenses for [{BASE_MODEL_NAME}](https://huggingface.co/{BASE_MODEL_ID}), trained as part of the [HatCat / Fractal Telescope Web](https://github.com/p0ss/HatCat) interpretability stack.

## What are these?

These are **trained linear probes** (lenses) that detect concept activations in a language model's hidden states. Each lens is a small classifier that fires when its corresponding concept is active during inference.

This lens pack contains **{CONCEPT_COUNT} concepts** across **{LAYER_COUNT} layers**, organized into a hierarchical ontology based on SUMO-WordNet.

## Usage

```python
from hatcat.registry import LensPackRegistry

# Load the lens pack
registry = LensPackRegistry()
lens_pack = registry.load("{LENS_PACK_ID}")

# Get concept scores during inference
with lens_pack.attach(model) as hat:
    outputs = model.generate(inputs)
    concept_scores = hat.get_scores()  # Dict[concept_id, float]
```

See the [HatCat documentation](https://github.com/p0ss/HatCat) for full usage.

## Training Details

| Parameter | Value |
|-----------|-------|
| Base model | {BASE_MODEL_ID} |
| Concept pack | {CONCEPT_PACK_ID} |
| Total concepts | {CONCEPT_COUNT} |
| Layers | {LAYERS} |
| Training samples per concept | {N_TRAIN_POS} positive, {N_TRAIN_NEG} negative |
| Test samples per concept | {N_TEST_POS} positive, {N_TEST_NEG} negative |
| Minimum F1 threshold | {MIN_F1} |
| Sibling refinement | Yes (margin ranking loss) |

### Performance Summary

| Layer | Concepts | Mean F1 | Mean Accuracy |
|-------|----------|---------|---------------|
{LAYER_METRICS_TABLE}

## Ontology Structure

The concepts are organized hierarchically across 5 domains:

- **CreatedThings** ({DOMAIN_COUNTS.CreatedThings} concepts) - Artifacts, tools, structures
- **MindsAndAgents** ({DOMAIN_COUNTS.MindsAndAgents} concepts) - Cognitive processes, agents, intentions
- **PhysicalWorld** ({DOMAIN_COUNTS.PhysicalWorld} concepts) - Physical objects, processes, properties
- **Information** ({DOMAIN_COUNTS.Information} concepts) - Data, propositions, representations
- **LivingThings** ({DOMAIN_COUNTS.LivingThings} concepts) - Organisms, biological processes

Each layer represents a different depth in the ontology:
- Layer 0: Root concepts (most abstract)
- Layer 4: Leaf concepts (most specific)

## File Structure

```
{LENS_PACK_NAME}/
├── manifest.json           # Pack metadata and concept index
├── layer_0/
│   └── *.pt               # Lens weights for layer 0 concepts
├── layer_1/
│   └── *.pt
├── layer_2/
│   └── *.pt
├── layer_3/
│   └── *.pt
├── layer_4/
│   └── *.pt
└── logs/
    └── training_*.log     # Training logs with per-concept metrics
```

## Intended Use

These lenses are designed for:

- **Interpretability research** - Understanding what concepts a model represents
- **Concept monitoring** - Real-time detection of concept activations during inference
- **Steering experiments** - Using lens directions for activation steering
- **Alignment research** - Building oversight systems (CAT, HUSH) on top of concept detection

## Limitations

- Lenses are trained on synthetic examples generated by an LLM - they detect concepts as represented in training data, not ground truth
- Performance varies by concept; some abstract concepts are harder to detect than concrete ones
- Sibling confusion can occur for closely related concepts (mitigated by sibling refinement)
- Lenses are specific to this base model; they won't transfer to other architectures

## Citation

```bibtex
@software{hatcat2025,
  title = {HatCat: Headspace Ambient Transducer},
  author = {HatCat Contributors},
  year = {2025},
  url = {https://github.com/p0ss/HatCat}
}
```

## License

Apache 2.0 - see [LICENSE](https://github.com/p0ss/HatCat/blob/main/LICENSE)
