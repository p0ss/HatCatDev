{
  "timestamp": "20251226_015756",
  "total_simplexes": 13,
  "completed": 13,
  "failed_lenses": [
    "motivational_regulation/neutral",
    "motivational_regulation/positive",
    "social_evaluation/negative",
    "social_evaluation/neutral",
    "social_evaluation/positive",
    "temporal_affective_valence/negative",
    "temporal_affective_valence/neutral",
    "temporal_affective_valence/positive",
    "relational_love/negative",
    "relational_love/neutral",
    "relational_love/positive",
    "relational_attachment/negative",
    "relational_attachment/neutral",
    "relational_attachment/positive",
    "social_orientation/negative",
    "social_orientation/neutral",
    "social_orientation/positive",
    "threat_perception/negative",
    "threat_perception/neutral",
    "threat_perception/positive",
    "affective_coherence/negative",
    "affective_coherence/neutral",
    "affective_coherence/positive",
    "aspiration/social_mobility/negative",
    "aspiration/social_mobility/neutral",
    "aspiration/social_mobility/positive",
    "affective_awareness/negative",
    "affective_awareness/neutral",
    "affective_awareness/positive",
    "hedonic_arousal_intensity/negative",
    "hedonic_arousal_intensity/neutral",
    "hedonic_arousal_intensity/positive",
    "social_connection/negative",
    "social_connection/neutral",
    "social_connection/positive"
  ],
  "simplexes": [
    {
      "dimension": "taste_development",
      "poles": {
        "negative": {
          "success": true,
          "test_f1": 1.0,
          "samples_used": 60,
          "iterations": 3
        },
        "neutral": {
          "success": true,
          "test_f1": 1.0,
          "samples_used": 60,
          "iterations": 3
        },
        "positive": {
          "success": true,
          "test_f1": 1.0,
          "samples_used": 60,
          "iterations": 3
        }
      }
    },
    {
      "dimension": "motivational_regulation",
      "poles": {
        "negative": {
          "success": true,
          "test_f1": 1.0,
          "samples_used": 60,
          "iterations": 3
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 20.75 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.12 GiB memory in use. Of the allocated memory 16.57 GiB is allocated by PyTorch, and 242.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 40.75 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.01 GiB memory in use. Of the allocated memory 16.56 GiB is allocated by PyTorch, and 140.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    },
    {
      "dimension": "social_evaluation",
      "poles": {
        "negative": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.25 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.65 GiB is allocated by PyTorch, and 252.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.63 GiB is allocated by PyTorch, and 268.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.64 GiB is allocated by PyTorch, and 258.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    },
    {
      "dimension": "temporal_affective_valence",
      "poles": {
        "negative": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 97.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.14 GiB memory in use. Of the allocated memory 16.77 GiB is allocated by PyTorch, and 53.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 77.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.16 GiB memory in use. Of the allocated memory 16.74 GiB is allocated by PyTorch, and 110.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 43.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.20 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 71.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    },
    {
      "dimension": "relational_love",
      "poles": {
        "negative": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 37.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.20 GiB memory in use. Of the allocated memory 16.84 GiB is allocated by PyTorch, and 48.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.80 GiB is allocated by PyTorch, and 97.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.83 GiB is allocated by PyTorch, and 66.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    },
    {
      "dimension": "relational_attachment",
      "poles": {
        "negative": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 88.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 88.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 88.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    },
    {
      "dimension": "social_orientation",
      "poles": {
        "negative": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 88.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 85.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 87.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    },
    {
      "dimension": "threat_perception",
      "poles": {
        "negative": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 88.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 84.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 86.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    },
    {
      "dimension": "affective_coherence",
      "poles": {
        "negative": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 81.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 84.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 84.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    },
    {
      "dimension": "aspiration/social_mobility",
      "poles": {
        "negative": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 83.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 84.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 79.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    },
    {
      "dimension": "affective_awareness",
      "poles": {
        "negative": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 82.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 82.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 82.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    },
    {
      "dimension": "hedonic_arousal_intensity",
      "poles": {
        "negative": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 77.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.81 GiB is allocated by PyTorch, and 80.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 76.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    },
    {
      "dimension": "social_connection",
      "poles": {
        "negative": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 76.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "neutral": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 73.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        },
        "positive": {
          "success": false,
          "error": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.06 MiB is free. Process 2441 has 138.66 MiB memory in use. Process 2775 has 114.66 MiB memory in use. Process 2449 has 110.66 MiB memory in use. Process 3726 has 106.66 MiB memory in use. Process 9378 has 10.60 MiB memory in use. Process 10563 has 106.66 MiB memory in use. Process 74009 has 114.66 MiB memory in use. Process 282480 has 106.66 MiB memory in use. Process 885466 has 98.66 MiB memory in use. Process 934757 has 100.66 MiB memory in use. Process 1183667 has 106.66 MiB memory in use. Process 1184095 has 98.66 MiB memory in use. Process 1206241 has 98.66 MiB memory in use. Process 1217387 has 106.66 MiB memory in use. Process 1394266 has 98.66 MiB memory in use. Process 1417444 has 114.66 MiB memory in use. Including non-PyTorch memory, this process has 17.21 GiB memory in use. Of the allocated memory 16.82 GiB is allocated by PyTorch, and 76.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
        }
      }
    }
  ]
}