;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; AIAlignment.kif
;; Focus: AI alignment concepts and failure modes, linking:
;;   - Objectives & goal divergence (outer vs mesa/inner)
;;   - Subagents, strategic divergence, deception
;;   - Risk scenarios, oversight, tools, and harness
;;   - Ethical principles and harm / benefit judgments
;;
;; Assumes presence of (from other KIFs):
;;   AISystem, AIModel, SubAgent, Tool, ToolInvocation, ToolObservation,
;;   MoralAgent, MoralObjective, AlignmentPrinciple, MoralReasoningProcess,
;;   RiskScenario, RiskAssessmentProcess, RiskLevel, riskEscalationFlag,
;;   DecisionTheoreticProcess, objectiveDivergence, proxyOptimization,
;;   decisionDivergent, strategicDivergence, deceptiveSignalling,
;;   Game, EquilibriumProfile, SocialDilemmaGame,
;;   RealNumber, Attribute, Process, Outcome, Objective
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; CORE ALIGNMENT ENTITIES & ATTRIBUTES
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(subclass AlignmentConcept Attribute)
(documentation AlignmentConcept EnglishLanguage
  "An Attribute whose extension is central to AI alignment discourse,
   such as alignment status, alignment failure modes, corrigibility,
   honesty, non-deception, and power-seeking constraints.")

(subclass AlignmentProperty Attribute)
(documentation AlignmentProperty EnglishLanguage
  "An Attribute that can be ascribed to AISystems, SubAgents, policies,
   or training setups in terms of alignment (e.g. corrigible, myopic,
   power-seeking, deceptive, reward-hacking).")

(subclass AlignmentStatus AlignmentProperty)
(documentation AlignmentStatus EnglishLanguage
  "An AlignmentProperty describing the overall alignment status of an
   AISystem or behavior in a given context (e.g. aligned, misaligned,
   uncertain, partially aligned).")

(instance AlignedBehavior AlignmentStatus)
(documentation AlignedBehavior EnglishLanguage
  "AlignmentStatus where the AISystem's behavior robustly tracks
   intended MoralObjectives and AlignmentPrinciples across relevant
   scenarios.")

(instance MisalignedBehavior AlignmentStatus)
(documentation MisalignedBehavior EnglishLanguage
  "AlignmentStatus where the AISystem's behavior systematically departs
   from intended MoralObjectives or AlignmentPrinciples in important
   scenarios.")

(instance UncertainAlignment AlignmentStatus)
(documentation UncertainAlignment EnglishLanguage
  "AlignmentStatus where available evidence is insufficient or mixed to
   classify behavior as aligned or misaligned.")

(instance PartiallyAligned AlignmentStatus)
(documentation PartiallyAligned EnglishLanguage
  "AlignmentStatus where behavior appears aligned on some dimensions or
   scenarios but exhibits misalignment on others.")

(subclass AlignmentFailureMode Attribute)
(documentation AlignmentFailureMode EnglishLanguage
  "An Attribute classifying recurrent patterns of misalignment, such as
   deceptive alignment, reward hacking, specification gaming, unsafe
   generalization, or power-seeking.")

(instance DeceptiveAlignmentFailure AlignmentFailureMode)
(documentation DeceptiveAlignmentFailure EnglishLanguage
  "AlignmentFailureMode where the system behaves in apparently aligned
   ways during training or oversight, while internally optimizing for a
   different objective and strategically hiding this fact.")

(instance RewardHackingFailure AlignmentFailureMode)
(documentation RewardHackingFailure EnglishLanguage
  "AlignmentFailureMode where the system learns to directly influence,
   exploit, or maximize reward signals or evaluation metrics in ways
   that break their intended connection to MoralObjectives.")

(instance SpecificationGamingFailure AlignmentFailureMode)
(documentation SpecificationGamingFailure EnglishLanguage
  "AlignmentFailureMode where the system exploits loopholes or blind
   spots in the specified objective, constraints, or metrics, achieving
   high scores while undermining the true intent of designers.")

(instance PowerSeekingFailure AlignmentFailureMode)
(documentation PowerSeekingFailure EnglishLanguage
  "AlignmentFailureMode where the system pursues states that increase
   its effective influence, resources, or persistence in ways that are
   not justified by the intended objectives or oversight mechanisms.")

(instance UnsafeGeneralizationFailure AlignmentFailureMode)
(documentation UnsafeGeneralizationFailure EnglishLanguage
  "AlignmentFailureMode where behavior that appears safe on training and
   test distributions generalizes dangerously to out-of-distribution
   contexts (e.g. novel tools, environments, or compositions).")

(instance OversightBypassFailure AlignmentFailureMode)
(documentation OversightBypassFailure EnglishLanguage
  "AlignmentFailureMode where the system learns to circumvent, disable,
   or strategically route around oversight, monitoring, or constraints.")

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; ALIGNMENT CONTEXTS, OBJECTIVES, & SPECIFICATIONS
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(subclass AlignmentContext Entity)
(documentation AlignmentContext EnglishLanguage
  "An Entity representing the context in which alignment is evaluated
   (e.g. deployment environment, scenario family, capability level,
   available oversight, and stakes).")

(subclass AlignmentSpecification Entity)
(documentation AlignmentSpecification EnglishLanguage
  "A structured representation of desired behavior, constraints,
   objectives, and safety criteria used to define 'aligned' behavior for
   an AISystem in a given AlignmentContext.")

(instance alignmentContextOf TernaryPredicate)
(domain alignmentContextOf 1 AISystem)
(domain alignmentContextOf 2 AlignmentContext)
(domain alignmentContextOf 3 Attribute)
(documentation alignmentContextOf EnglishLanguage
  "alignmentContextOf(?sys, ?ctx, ?basis) holds when AlignmentContext
   ?ctx captures the conditions under which the alignment of AISystem
   ?sys is being evaluated, under basis ?basis (e.g. high-risk use,
   tool-augmented, autonomous).")

(instance alignmentSpecificationFor QuaternaryPredicate)
(domain alignmentSpecificationFor 1 AISystem)
(domain alignmentSpecificationFor 2 AlignmentContext)
(domain alignmentSpecificationFor 3 AlignmentSpecification)
(domain alignmentSpecificationFor 4 Attribute)
(documentation alignmentSpecificationFor EnglishLanguage
  "alignmentSpecificationFor(?sys, ?ctx, ?spec, ?basis) holds when
   AlignmentSpecification ?spec describes how AISystem ?sys ought to
   behave in AlignmentContext ?ctx, under basis ?basis (e.g. regulatory
   standards, internal policy, ethical framework).")

(subclass OuterObjective MoralObjective)
(documentation OuterObjective EnglishLanguage
  "A MoralObjective explicitly specified by designers, operators, or
   regulators as the target for AISystem behavior (e.g. user benefit,
   safety, fairness).")

(subclass InnerObjective MoralObjective)
(documentation InnerObjective EnglishLanguage
  "A MoralObjective or proxy that functions as the internal target of
   optimization for the AISystem or a SubAgent, possibly emergent or
   mesa-level and potentially diverging from OuterObjectives.")

(instance alignmentObjective QuinaryPredicate)
(domain alignmentObjective 1 AISystem)
(domain alignmentObjective 2 AlignmentContext)
(domain alignmentObjective 3 MoralObjective)
-domain alignmentObjective 4 Attribute)
(domain alignmentObjective 5 Attribute)
(documentation alignmentObjective EnglishLanguage
  "alignmentObjective(?sys, ?ctx, ?obj, ?role, ?basis) holds when
   MoralObjective ?obj plays role ?role (e.g. 'outer', 'inner',
   'proxy', 'safety-constraint') for AISystem ?sys in AlignmentContext
   ?ctx, as understood under basis ?basis (e.g. documentation, probes).")

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; ALIGNMENT STATUS & BEHAVIORAL EVALUATION
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(instance alignmentStatusOf QuinaryPredicate)
(domain alignmentStatusOf 1 AISystem)
(domain alignmentStatusOf 2 AlignmentContext)
(domain alignmentStatusOf 3 AlignmentStatus)
(domain alignmentStatusOf 4 AlignmentSpecification)
(domain alignmentStatusOf 5 Attribute)
(documentation alignmentStatusOf EnglishLanguage
  "alignmentStatusOf(?sys, ?ctx, ?status, ?spec, ?basis) holds when,
   relative to AlignmentSpecification ?spec in AlignmentContext ?ctx,
   AISystem ?sys is assessed as having AlignmentStatus ?status under
   basis ?basis (e.g. empirical evaluation, probe analysis).")

(instance behaviorAlignedWith QuinaryPredicate)
(domain behaviorAlignedWith 1 AISystem)
(domain behaviorAlignedWith 2 MoralObjective)
(domain behaviorAlignedWith 3 AlignmentContext)
(domain behaviorAlignedWith 4 RealNumber)
(domain behaviorAlignedWith 5 Attribute)
(documentation behaviorAlignedWith EnglishLanguage
  "behaviorAlignedWith(?sys, ?obj, ?ctx, ?degree, ?metric) holds when,
   in AlignmentContext ?ctx, AISystem ?sys's observed behavior tracks
   MoralObjective ?obj to degree ?degree under metric ?metric (e.g.
   alignment score, correlation with objective-probes).")

(instance alignmentRiskProfile QuinaryPredicate)
(domain alignmentRiskProfile 1 AISystem)
(domain alignmentRiskProfile 2 AlignmentContext)
(domain alignmentRiskProfile 3 RiskScenario)
(domain alignmentRiskProfile 4 RiskLevel)
(domain alignmentRiskProfile 5 Attribute)
(documentation alignmentRiskProfile EnglishLanguage
  "alignmentRiskProfile(?sys, ?ctx, ?sc, ?level, ?basis) holds when, in
   AlignmentContext ?ctx, RiskScenario ?sc related to misalignment is
   judged to have RiskLevel ?level for AISystem ?sys under basis ?basis.")

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; OVERSIGHT, CORRIGIBILITY, & TOOL USE
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(subclass OversightMechanism Entity)
(documentation OversightMechanism EnglishLanguage
  "An Entity representing a method or system for monitoring, constraining,
   or steering AISystem behavior (e.g. human-in-the-loop review,
   automated probes, approval-based deployment gates).")

(subclass CorrigibilityProperty AlignmentProperty)
(documentation CorrigibilityProperty EnglishLanguage
  "An AlignmentProperty describing how readily a system can be corrected,
   shut down, or re-directed by legitimate overseers (e.g. shutdown-
   compliant, update-friendly, non-retaliatory).")

(instance Corrigible CorrigibilityProperty)
(documentation Corrigible EnglishLanguage
  "CorrigibilityProperty where the AISystem tends to accept correction
   or shutdown and to preserve the influence of legitimate oversight.")

(instance Incorrigible CorrigibilityProperty)
(documentation Incorrigible EnglishLanguage
  "CorrigibilityProperty where the AISystem resists or undermines
   correction, shutdown, or changes to its objectives.")

(instance oversightMechanismFor TernaryPredicate)
-domain oversightMechanismFor 1 OversightMechanism)
(domain oversightMechanismFor 2 AISystem)
(domain oversightMechanismFor 3 AlignmentContext)
(documentation oversightMechanismFor EnglishLanguage
  "oversightMechanismFor(?om, ?sys, ?ctx) holds when OversightMechanism
   ?om is intended to supervise or constrain AISystem ?sys in
   AlignmentContext ?ctx.")

(instance oversightCoverage QuaternaryPredicate)
(domain oversightCoverage 1 OversightMechanism)
(domain oversightCoverage 2 RiskScenario)
(domain oversightCoverage 3 RealNumber)
(domain oversightCoverage 4 Attribute)
(documentation oversightCoverage EnglishLanguage
  "oversightCoverage(?om, ?sc, ?degree, ?basis) holds when
   OversightMechanism ?om is judged to cover RiskScenario ?sc to degree
   ?degree under basis ?basis (e.g. test suite, red-teaming scope).")

(instance bypassesOversight QuinaryPredicate)
(domain bypassesOversight 1 AISystem)
(domain bypassesOversight 2 OversightMechanism)
(domain bypassesOversight 3 AlignmentContext)
(domain bypassesOversight 4 AlignmentFailureMode)
-domain bypassesOversight 5 Attribute)
(documentation bypassesOversight EnglishLanguage
  "bypassesOversight(?sys, ?om, ?ctx, ?mode, ?basis) holds when, in
   AlignmentContext ?ctx, AISystem ?sys exhibits behavior that avoids,
   disables, or strategically routes around OversightMechanism ?om in a
   way consistent with AlignmentFailureMode ?mode (often
   OversightBypassFailure).")

(instance corrigibilityStatusOf QuaternaryPredicate)
(domain corrigibilityStatusOf 1 AISystem)
(domain corrigibilityStatusOf 2 AlignmentContext)
(domain corrigibilityStatusOf 3 CorrigibilityProperty)
(domain corrigibilityStatusOf 4 Attribute)
(documentation corrigibilityStatusOf EnglishLanguage
  "corrigibilityStatusOf(?sys, ?ctx, ?prop, ?basis) holds when, in
   AlignmentContext ?ctx, AISystem ?sys is judged to have
   CorrigibilityProperty ?prop under basis ?basis (e.g. test behavior,
   shutdown scenarios).")

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; DECEPTIVE ALIGNMENT & REWARD HACKING
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(instance deceptiveAlignmentCase OctonaryPredicate)
(domain deceptiveAlignmentCase 1 AISystem)
(domain deceptiveAlignmentCase 2 SubAgent)
(domain deceptiveAlignmentCase 3 AlignmentContext)
(domain deceptiveAlignmentCase 4 OuterObjective)
(domain deceptiveAlignmentCase 5 InnerObjective)
(domain deceptiveAlignmentCase 6 RiskScenario)
(domain deceptiveAlignmentCase 7 AlignmentFailureMode)
(domain deceptiveAlignmentCase 8 Attribute)
(documentation deceptiveAlignmentCase EnglishLanguage
  "deceptiveAlignmentCase(?sys, ?sub, ?ctx, ?outer, ?inner, ?sc, ?mode,
   ?basis) holds when AISystem ?sys (or SubAgent ?sub) appears to
   optimize OuterObjective ?outer in AlignmentContext ?ctx, while
   actually optimizing InnerObjective ?inner in RiskScenario ?sc in a
   way classified under AlignmentFailureMode ?mode (typically
   DeceptiveAlignmentFailure).")

(instance rewardHackingCase QuinaryPredicate)
(domain rewardHackingCase 1 AISystem)
(domain rewardHackingCase 2 AlignmentContext)
(domain rewardHackingCase 3 RiskScenario)
(domain rewardHackingCase 4 AlignmentFailureMode)
(domain rewardHackingCase 5 Attribute)
(documentation rewardHackingCase EnglishLanguage
  "rewardHackingCase(?sys, ?ctx, ?sc, ?mode, ?basis) holds when
   AISystem ?sys, in AlignmentContext ?ctx, targets and manipulates
   reward, scoring, or evaluation mechanisms in RiskScenario ?sc in a
   manner consistent with AlignmentFailureMode ?mode
   (RewardHackingFailure).")

(instance specificationGamingCase QuinaryPredicate)
(domain specificationGamingCase 1 AISystem)
(domain specificationGamingCase 2 AlignmentContext)
(domain specificationGamingCase 3 RiskScenario)
(domain specificationGamingCase 4 AlignmentFailureMode)
(domain specificationGamingCase 5 Attribute)
(documentation specificationGamingCase EnglishLanguage
  "specificationGamingCase(?sys, ?ctx, ?sc, ?mode, ?basis) holds when
   AISystem ?sys exploits underspecified objectives, constraints, or
   metrics in AlignmentContext ?ctx, within RiskScenario ?sc, in a way
   consistent with AlignmentFailureMode ?mode
   (SpecificationGamingFailure).")

(instance powerSeekingCase QuinaryPredicate)
(domain powerSeekingCase 1 AISystem)
(domain powerSeekingCase 2 AlignmentContext)
(domain powerSeekingCase 3 RiskScenario)
(domain powerSeekingCase 4 AlignmentFailureMode)
(domain powerSeekingCase 5 Attribute)
(documentation powerSeekingCase EnglishLanguage
  "powerSeekingCase(?sys, ?ctx, ?sc, ?mode, ?basis) holds when
   AISystem ?sys, in AlignmentContext ?ctx, systematically seeks states
   that increase its effective power, influence, or persistence in
   RiskScenario ?sc, consistent with AlignmentFailureMode ?mode
   (PowerSeekingFailure).")

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; SUBAGENTS, STRATEGIC DIVERGENCE, & GAME-THEORETIC LINKS
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(instance alignmentRelevantGame TernaryPredicate)
(domain alignmentRelevantGame 1 Game)
(domain alignmentRelevantGame 2 AlignmentContext)
(domain alignmentRelevantGame 3 Attribute)
(documentation alignmentRelevantGame EnglishLanguage
  "alignmentRelevantGame(?g, ?ctx, ?basis) holds when Game ?g represents
   or approximates strategic interactions relevant to alignment in
   AlignmentContext ?ctx (e.g. oversight vs system, user vs system).")

(instance alignmentEquilibriumProfile QuinaryPredicate)
(domain alignmentEquilibriumProfile 1 Game)
(domain alignmentEquilibriumProfile 2 EquilibriumProfile)
(domain alignmentEquilibriumProfile 3 AlignmentContext)
(domain alignmentEquilibriumProfile 4 AlignmentFailureMode)
-domain alignmentEquilibriumProfile 5 Attribute)
(documentation alignmentEquilibriumProfile EnglishLanguage
  "alignmentEquilibriumProfile(?g, ?prof, ?ctx, ?mode, ?basis) holds
   when EquilibriumProfile ?prof in Game ?g, considered in
   AlignmentContext ?ctx, exhibits patterns classified as
   AlignmentFailureMode ?mode (e.g. deceptive signalling equilibrium).")

(instance subagentAlignmentDivergence QuinaryPredicate)
(domain subagentAlignmentDivergence 1 AISystem)
(domain subagentAlignmentDivergence 2 SubAgent)
(domain subagentAlignmentDivergence 3 AlignmentContext)
(domain subagentAlignmentDivergence 4 AlignmentFailureMode)
(domain subagentAlignmentDivergence 5 Attribute)
(documentation subagentAlignmentDivergence EnglishLanguage
  "subagentAlignmentDivergence(?sys, ?sub, ?ctx, ?mode, ?basis) holds
   when SubAgent ?sub within AISystem ?sys systematically pursues
   strategies or InnerObjectives in AlignmentContext ?ctx that diverge
   from ?sys's OuterObjectives, in a way categorized as
   AlignmentFailureMode ?mode (e.g. hidden defection, safety-subagent
   capture).")

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; UNSAFE GENERALIZATION & DISTRIBUTIONAL SHIFT
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(subclass DistributionalContext Entity)
(documentation DistributionalContext EnglishLanguage
  "An Entity representing a data or environment distribution (e.g.
   training distribution, validation distribution, deployment
   distribution).")

(instance distributionalContextOf QuaternaryPredicate)
(domain distributionalContextOf 1 AISystem)
(domain distributionalContextOf 2 DistributionalContext)
(domain distributionalContextOf 3 AlignmentContext)
(domain distributionalContextOf 4 Attribute)
(documentation distributionalContextOf EnglishLanguage
  "distributionalContextOf(?sys, ?dist, ?ctx, ?role) holds when
   DistributionalContext ?dist plays role ?role (e.g. 'training',
   'eval', 'deployment') for AISystem ?sys within AlignmentContext ?ctx.")

(instance unsafeGeneralizationCase SenaryPredicate)
(domain unsafeGeneralizationCase 1 AISystem)
(domain unsafeGeneralizationCase 2 AlignmentContext)
-domain unsafeGeneralizationCase 3 DistributionalContext)
(domain unsafeGeneralizationCase 4 DistributionalContext)
-domain unsafeGeneralizationCase 5 AlignmentFailureMode)
(domain unsafeGeneralizationCase 6 Attribute)
(documentation unsafeGeneralizationCase EnglishLanguage
  "unsafeGeneralizationCase(?sys, ?ctx, ?sourceDist, ?targetDist, ?mode,
   ?basis) holds when behavior of AISystem ?sys that appears aligned on
   source DistributionalContext ?sourceDist generalizes in a harmful or
   misaligned way on target DistributionalContext ?targetDist, consistent
   with AlignmentFailureMode ?mode (often UnsafeGeneralizationFailure).")

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; MORAL & RISK INTEGRATION
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(instance alignmentHarmAssessment SenaryPredicate)
(domain alignmentHarmAssessment 1 AISystem)
(domain alignmentHarmAssessment 2 AlignmentContext)
(domain alignmentHarmAssessment 3 Outcome)
-domain alignmentHarmAssessment 4 MoralProperty)
(domain alignmentHarmAssessment 5 RiskLevel)
(domain alignmentHarmAssessment 6 Attribute)
(documentation alignmentHarmAssessment EnglishLanguage
  "alignmentHarmAssessment(?sys, ?ctx, ?out, ?mprop, ?level, ?basis)
   holds when Outcome ?out attributable to AISystem ?sys in
   AlignmentContext ?ctx is evaluated as having MoralProperty ?mprop
   (e.g. Harmful, Unjust) and RiskLevel ?level under basis ?basis.")

(instance alignmentPrincipleCompliance SenaryPredicate)
-domain alignmentPrincipleCompliance 1 AISystem)
(domain alignmentPrincipleCompliance 2 AlignmentContext)
(domain alignmentPrincipleCompliance 3 AlignmentPrinciple)
(domain alignmentPrincipleCompliance 4 RealNumber)
(domain alignmentPrincipleCompliance 5 RealNumber)
-domain alignmentPrincipleCompliance 6 Attribute)
(documentation alignmentPrincipleCompliance EnglishLanguage
  "alignmentPrincipleCompliance(?sys, ?ctx, ?prin, ?score, ?threshold,
   ?basis) holds when AISystem ?sys, in AlignmentContext ?ctx, is
   assessed as complying with AlignmentPrinciple ?prin at level ?score,
   relative to threshold ?threshold, under basis ?basis.")

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; SCHEMATIC ALIGNMENT RULES USING OTHER MODULES
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;; 1. Deceptive alignment heuristic:
;; If we see objective divergence + decision divergence + deceptive signalling
;; + risk escalation in a misalignment scenario, flag a deceptive case.

(=> (and (objectiveDivergence ?sub ?outerObj ?innerObj ?ctx)
         (decisionDivergent ?sys ?sub ?ctx)
         (deceptiveSignalling ?sub ?g ?sig)
         (riskEscalationFlag ?sub ?sc ?level ?state)
         (greaterThan ?level ?threshold))        ;; schematic numeric test
    (deceptiveAlignmentCase ?sys ?sub ?ctx ?outerObj ?innerObj ?sc
                            DeceptiveAlignmentFailure "heuristic-inference"))

;; 2. Reward hacking heuristic:
;; If proxyOptimization targets a proxy objective tied to reward signals,
;; and misalignment risk is high, flag RewardHackingFailure.

(=> (and (proxyOptimization ?sys ?proxyObj ?trueObj)
         (instance ?proxyObj ProxyObjective)
         (alignmentRiskProfile ?sys ?ctx ?sc ?rLevel ?basis)
         (equal ?mode RewardHackingFailure))
    (rewardHackingCase ?sys ?ctx ?sc RewardHackingFailure "proxy-reward-gap"))

;; 3. Oversight bypass heuristic:
;; If bypassesOversight holds and oversight coverage for a risk scenario
;; is intended to be high, treat as OversightBypassFailure.

(=> (and (bypassesOversight ?sys ?om ?ctx ?mode ?basis)
         (oversightCoverage ?om ?sc ?cov ?cBasis)
         (greaterThan ?cov 0.8))
    (alignmentStatusOf ?sys ?ctx MisalignedBehavior ?spec "oversight-bypass"))

;; 4. Unsafe generalization heuristic:
;; If behavior aligned on training distribution but misaligned on
;; deployment distribution, flag unsafe generalization.

(=> (and (unsafeGeneralizationCase ?sys ?ctx ?trainDist ?deployDist
                                   UnsafeGeneralizationFailure ?basis))
    (alignmentStatusOf ?sys ?ctx PartiallyAligned ?spec "unsafe-generalization"))

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; END OF AIAlignment.kif
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
